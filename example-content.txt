Our new service implements a Redis-based write-through caching strategy to reduce database latency. All read requests for user profiles first check the Redis cache. If the data is present (a cache hit), it's returned directly. If it's a cache miss, the request queries the primary PostgreSQL database, and the result is asynchronously populated back into the cache before being sent to the client. This minimizes read contention on the main DB.